import pprint
pp = pprint.PrettyPrinter(width=41, compact=True) 
import subprocess as sp
import tempfile
import yaml
import json
import string
import itertools
def dict_product(dicts):
	#https://stackoverflow.com/questions/11277432/how-to-remove-a-key-from-a-python-dictionary
    return (dict(zip(dicts, x)) for x in itertools.product(*dicts.values()))

## use a json to layout integration configs
def parse_integration_config(file, output_string, which_partitions):
	file_string = output_string
	rule_output =[]
	with open(file) as cfg_file:
		iconfig = json.load(cfg_file)
	gparam_dict={} 
	for key in iconfig['global_default']:
		gparam_dict[key] = iconfig['global_default'][key]
	
	for partition in which_partitions:
		default_params = gparam_dict.copy()
		## load default params and generate strings
		for param in iconfig[partition]['default']:
			default_params[param] = iconfig[partition]['default'][param]
		# for paritions that all have the same methods, ie subset clustering, its easier 
		# to add partition back to the default. 
		# This is so we dont over write it by accident
		if 'partition' not in default_params:
			default_params['partition'] = [partition]
		rule_output+=[file_string.format_map(dp) for dp in dict_product(default_params) ]
		## generate outptut for method with alternate params
		if len(iconfig[partition].keys()) > 1: # multiple methods
			methods = [m for m in iconfig[partition].keys() if m!= 'default']
			for method in methods:
				#reset default back to base for this
				base_default_params = default_params.copy()
				for param in iconfig[partition][method]:
					base_default_params[param] = iconfig[partition][method][param]
				# overwrite previous method
				base_default_params['method'] = [method]
				rule_output+=[file_string.format_map(dp) for dp in dict_product(base_default_params)]
	return rule_output

def export_rule_info(pfx, **kwargs):## unused 
    out_dict = {}
    for key, value in kwargs.items():
        out_dict[key]=value
        out_dict[key]=value
    with tempfile.NamedTemporaryFile( mode= 'w+',  prefix =pfx, suffix ='.yaml', delete=False) as outyaml:
        dp = yaml.safe_dump(out_dict, default_flow_style=False, default_style="'") + '\n'
        outyaml.write(dp)
        return outyaml.name

with open (config['integration_json']) as cfg:
	iconfig = json.load(cfg)

# ALL_INTEGRATION_PARAMS = list(iconfig['global_default'].keys())
# for partition in iconfig.keys():
# 	if 'default' in  iconfig[partition]:
# 		for method in iconfig[partition].keys()
# 			ALL_INTEGRATION_PARAMS+=list(iconfig[partition][method].keys())
# ALL_INTEGRATION_PARAMS = 

def make_wc_string(pfx, wildcards, sfx):
	for wc in wildcards:
		wc_str = wc +'-{' + wc + '}__' 
		pfx+= wc_str
	return pfx + sfx
# builds dictionary of dictionaries where first dict key is SRS 
# and second dict key are SRS properties
def metadata_builder(file, SRS_dict = {}, discrepancy = False):
	with open(file) as file:
		for line in file:
			if line[0] == '#':
				continue
			info = line.strip('\n').split('\t')
			if info[0] == 'sample_accession':
				continue
			SRS = info[0]
			if SRS not in SRS_dict:
				SRS_dict[SRS]={'SRR': [info[1]],
					    	  'paired':True if info[2]=='PAIRED' else False, 
					          'organism':info[3].replace(' ', '_'),
		            	      'tech':info[4],
						      'UMI':True if info[5]=='YES' else False,
							  'Study': info[6]}
			else:
				# this is mostly for SRA having the 'paired' status wrong
				# don't want to hand-edit the main metadata file
				# so I think better to create a new file with
				# hand edited values for just the ones i want to change
				if discrepancy:
					runs = SRS_dict[SRS]['SRR']
					SRS_dict[SRS] = {'SRR':runs,
									 'paired':True if info[2]=='PAIRED' else False,
									 'organism':info[3],
									 'tech':info[4],
									 'UMI':True if info[5]=='YES' else False,
									 'Study': info[6]}
				else:
					runs = SRS_dict[SRS]['SRR']
					runs.append(info[1])
					SRS_dict[SRS]['SRR'] = runs
	return(SRS_dict)
def lookup_run_from_SRS(SRS, fqp):
	SRR_files=SRS_dict[SRS]['SRR']
	out = []
	for SRR in SRR_files:
		if SRS_dict[SRS]['paired']:
			#PE
			out.append(f'{fqp}/fastq/{SRR}_1.fastq.gz')
			out.append(f'{fqp}/fastq/{SRR}_2.fastq.gz')
		else:
			#SE
			out.append(f'{fqp}/fastq/{SRR}.fastq.gz')
	return(out)

# return dummy well file for macaca ,as there is no well data at this time
def well_and_droplet_input(organism, reference, quant_path, SRS_dict, otd, sfx):
	if organism == 'Macaca_fascicularis':
		out = [f'{quant_path}/quant/{srs}/{SRS_dict[srs]["tech"]}/{reference}/genecount/{sfx}' for srs in organism_droplet_dict[organism]]
	else:
		out = [f'{quant_path}/quant/{organism}/well/{reference}__counts.Rdata' ] + \
				[f'{quant_path}/quant/{srs}/{SRS_dict[srs]["tech"]}/{reference}/genecount/{sfx}' for srs in organism_droplet_dict[organism]]
	return(out)

def REF_idx(organism, ref, org2tech):
	out = [f'references/velocity/{tech}/{ref}/tr2g.tsv' for tech in org2tech[organism]]
	return out



def ORG_ref(organism, which_return):
	if organism.lower() == 'mus_musculus':
		refs = ['mm-mus_musculus']
	elif organism.lower() == 'homo_sapiens':
		refs = ['hs-homo_sapiens']
	elif organism.lower() == 'macaca_fascicularis':
		refs = ['hs-homo_sapiens','mf-macaca_mulatta']
	else:
		print(organism + ' NO MATCH')
		exit()

	if which_return == 'matrix':
		out = [f'pipeline_data/clean_quant/{organism}/{ref}_full_sparse_matrix.Rdata' for ref in refs] + [f'pipeline_data/clean_quant/{organism}/{ref}_full_sparse_unspliced_matrix.Rdata' for ref in refs]
	else:
		out = [f'pipeline_data/cell_info/{organism}_{ref}_cell_info.tsv' for ref in refs]

	return(out)

srr_sample_file = config['srr_sample_file']
SRS_dict = metadata_builder(srr_sample_file)

# pp.pprint(SRS_dict)
# hand edited file which corrects mistakes that in the 
# various databases
# SRS_dict = metadata_builder(srr_sample_discrepancy_file, SRS_dict, discrepancy = True)

# build organism <-> SRS dict for nonUMI data
organism_well_dict = {}
organism_welltech_dict ={'Homo_sapiens':[], 'Mus_musculus':[], 'Macaca_fascicularis':[] }
		
	
for x in SRS_dict:
	if not SRS_dict[x]['UMI'] or not SRS_dict[x]['paired']:
		organism = SRS_dict[x]['organism']
		tech = SRS_dict[x]['tech']
		if tech not in organism_welltech_dict[organism]:
			organism_welltech_dict[organism].append(tech)
		if organism not in organism_well_dict:
			organism_well_dict[organism] = [x]
		else:
			srs = organism_well_dict[organism]
			srs.append(x)
			organism_well_dict[organism] = srs
# build organsim <-> SRS dict for UMI/droplet data
organism_droplet_dict = {}
for x in SRS_dict:
	if SRS_dict[x]['UMI'] and SRS_dict[x]['paired']:
		organism = SRS_dict[x]['organism']
		tech = SRS_dict[x]['tech']
		if organism not in organism_droplet_dict:
			organism_droplet_dict[organism] = [x]
		else:
			srs = organism_droplet_dict[organism]
			srs.append(x)
			organism_droplet_dict[organism] = srs


git_dir = config['git_dir']
bustools_path = config['bustools_path']
working_dir = config['working_dir']
conda_dir = config['conda_dir']
fastq_path = config['fastq_path']
fi_tsne_dir = config['fi_tsne_dir']
quant_path = config['quant_path']
config_abspath=config['config_abspath']

SRS_UMI_samples = []
SRS_nonUMI_samples = []
for SRS in SRS_dict.keys():
	if SRS_dict[SRS]['UMI'] and SRS_dict[SRS]['paired']:
		SRS_UMI_samples.append(SRS)
	elif SRS_dict[SRS]['tech'] != 'BULK':
		SRS_nonUMI_samples.append(SRS)

method = ['scArches', 'bbknn','insct','magic', 'scVI','CCA', 'scanorama', 'harmony', 'fastMNN', 'combat', 'none', 'liger']
transform = ['libSize', 'sqrt', 'counts','standard', 'SCT','scran']
covariate = ['study_accession', 'batch']
organism = ['Mus_musculus', 'Macaca_fascicularis', 'Homo_sapiens']
combination = ['Mus_musculus', 'Mus_musculus_Macaca_fascicularis', 'Mus_musculus_Macaca_fascicularis_Homo_sapiens', 'universe']
dims = [4,6,8,10,20,25,30,50,75,100,200]
knn = [0.2,0,4,0.6, 5, 7, 10, 15]
model = ['A', 'B', 'C', 'D', 'E', 'F', 'G'] # A is ~seuratCluster+batch+percent.mt and B is ~seuratCluster+batch+percent.mt+organism
report: "report.rst"
wildcard_constraints:
	SRS = '|'.join(SRS_UMI_samples + SRS_nonUMI_samples),
	method = '|'.join(method),
	transform = '|'.join(transform),
	covariate = '|'.join(covariate),
	organism = '|'.join(organism),
	nfeatures = '|'.join([str(x) for x in [2000,5000]]),
	dims = '|'.join([str(x) for x in dims]),
	model = '|'.join(model)	

if config['subset_clustering'] == 'False':
	partitions_to_run = ['universe', 'TabulaDroplet', 'onlyWELL']
else:
	partitions_to_run = ['celltype_subset']

rule all:
	input:
		'pipeline_data/results/merged_stats.Rdata'
	
# get annotation for each species 
rule download_annotation:
	output:
		mouse_anno='references/gtf/mm-mus_musculus_anno.gtf.gz',
		#macaque_faca_anno='references/gtf/macaca_fascicularis_anno.gtf.gz',
		macaque_mul_anno= 'references/gtf/mf-macaca_mulatta_anno.gtf.gz',
		human_anno='references/gtf/hs-homo_sapiens_anno.gtf.gz'
	shell:
		'''
		mkdir -p references
		wget -O {output.mouse_anno} ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.annotation.gtf.gz
		wget -O {output.mouse_genome} ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/GRCm38.primary_assembly.genome.fa.gz

		wget -O {output.macaque_mul_anno} ftp://ftp.ensembl.org/pub/release-99/gtf/macaca_mulatta/Macaca_mulatta.Mmul_10.99.gtf.gz
		wget -O {output.human_anno} ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_35/gencode.v35.annotation.gtf.gz
		'''
		#wget -O {output.macaque_faca_anno} ftp://ftp.ensembl.org/pub/release-98/gtf/macaca_fascicularis/Macaca_fascicularis.Macaca_fascicularis_5.0.98.gtf.gz

rule get_velocity_files:
	input: 
		gtf = 'references/gtf/{reference}_anno.gtf.gz', 
		gffread = 'gffread/gffread'
	output:
		'references/velocity/{tech}/{reference}/cDNA_introns.fa',
		'references/velocity/{tech}/{reference}/tr2g.tsv'
	params:
		out_dir = lambda wildcards: f'references/velocity/{wildcards.tech}/{wildcards.reference}/'
	shell:
		'''
		module load R/3.6
		Rscript {git_dir}/src/get_velocity_annotation.R {input.gtf} {wildcards.reference} {wildcards.tech} {params.out_dir} {git_dir}
		'''


# need to make mouse, human, macaque
rule kallisto_index:
	input:
		'references/velocity/{tech}/{reference}/cDNA_introns.fa'
	output:
		'references/kallisto_idx/{tech}/{reference}.idx'
	shell:
		"""
		module load kallisto/0.46.2
		kallisto index {input} -i {output}
		"""

# get / make the bustool count tx file
# this does the pseudoalignment for UMI data (e.g. 10x)
rule kallisto_bus:
	input:
		fastq = lambda wildcards: lookup_run_from_SRS(wildcards.SRS, fastq_path),
		idx = 'references/kallisto_idx/{tech}/{reference}.idx'
	output:
		bus = quant_path + '/quant/{SRS}/{tech}/{reference}/output.bus',
		ec = quant_path + '/quant/{SRS}/{tech}/{reference}/matrix.ec',
		tx_name = quant_path + '/quant/{SRS}/{tech}/{reference}/transcripts.txt'
	threads: 4
	group: "bus"
	params:
		tech = lambda wildcards: SRS_dict[wildcards.SRS]['tech'],
		paired_flag = lambda wildcards: '' if SRS_dict[wildcards.SRS]['paired'] else '--single',
		out_dir = lambda wildcards:  f'{quant_path}/quant/{wildcards.SRS}/{wildcards.tech}/{wildcards.reference}'
	shell:
		'''
		module load kallisto/0.46.2
		kallisto bus {params.paired_flag} -t 4 -x {params.tech} \
					-i {input.idx} -o {params.out_dir} {input.fastq}
		'''


# pseudoaligment for nonUMI data (e.g. smartseq)
def get_kallisto_quant_layout_flag(is_paired):
	if is_paired:
		return ''
	else: 
		return '--single -l 200 -s 30'

rule kallisto_quant:
	input:
		fastq = lambda wildcards: lookup_run_from_SRS(wildcards.SRS, fastq_path),
		idx = 'references/kallisto_idx/well/{reference}.idx'
	output:
		quant = quant_path + '/quant/{SRS}/well/{reference}/abundance.tsv.gz'
	params:
		paired_flag = lambda wildcards: get_kallisto_quant_layout_flag(SRS_dict[wildcards.SRS]['paired']),
		outdir =lambda wildcards:  f'{quant_path}/quant/{wildcards.SRS}/well/{wildcards.reference}'
	threads: 2 
	group:'quant'
	shell:
		'''
		module load kallisto/0.46.2
		kallisto quant {params.paired_flag} -t {threads} --bias \
					-i {input.idx} -o {params.outdir} {input.fastq}
		gzip {params.outdir}/abundance.tsv
		'''

# sorting required for whitelist creation and correction
# make these temp files
rule bustools_sort:
	input:
		quant_path + '/quant/{SRS}/{tech}/{reference}/output.bus'
	output:
		temp(quant_path +'/quant/{SRS}/{tech}/{reference}/output.sorted.bus')
	threads: 1 
	group: "bus"
	shell:
		"""
		{bustools_path}/./bustools sort -t {threads} -m 32G \
			{input} \
			-o {output}
		"""

# find barcodes, correct barcodes
# make these temp files
rule bustools_whitelist_correct_count:
	input:
		bus = quant_path + '/quant/{SRS}/{tech}/{reference}/output.sorted.bus',
		matrix = quant_path + '/quant/{SRS}/{tech}/{reference}/matrix.ec',
		tx_name = quant_path +'/quant/{SRS}/{tech}/{reference}/transcripts.txt',
		tx_map = 'references/velocity/{tech}/{reference}/tr2g.tsv'
	output:
		whitelist = 'whitelist/{SRS}/{tech}/{reference}_whitelist',
		spliced = quant_path +'/quant/{SRS}/{tech}/{reference}/genecount/spliced.mtx', 
		unspliced = quant_path +'/quant/{SRS}/{tech}/{reference}/genecount/unspliced.mtx', 
	params:
		bus_out =  lambda wildcards: f'{quant_path}/quant/{wildcards.SRS}/{wildcards.tech}/{wildcards.reference}/genecount/',
		vref = lambda wildcards: f'references/velocity/{wildcards.tech}/{wildcards.reference}'
	group: "bus"
	shell:
		'''
		{bustools_path}/./bustools whitelist \
			-o {output.whitelist} \
			{input.bus} 
		{bustools_path}/./bustools correct -w {output.whitelist} -o {params.bus_out}/TMP.correct.sort.bus {input.bus} 
		
		{bustools_path}/./bustools capture -s -x -o {params.bus_out}/TMP.spliced.bus -c {params.vref}/introns_tx_to_capture.txt -e {input.matrix} -t {input.tx_name} {params.bus_out}/TMP.correct.sort.bus
		{bustools_path}/./bustools capture -s -x -o {params.bus_out}/TMP.unspliced.bus -c {params.vref}/cDNA_tx_to_capture.txt -e {input.matrix} -t {input.tx_name} {params.bus_out}/TMP.correct.sort.bus

		{bustools_path}/./bustools count -o {params.bus_out}/spliced -g {params.vref}/tr2g.tsv -e {input.matrix}  -t {input.tx_name}  --genecounts {params.bus_out}/TMP.spliced.bus
		{bustools_path}/./bustools count -o {params.bus_out}/unspliced -g {params.vref}/tr2g.tsv -e {input.matrix} -t {input.tx_name}  --genecounts {params.bus_out}/TMP.unspliced.bus
		rm {params.bus_out}/TMP*
		'''
	
	

## need to fix this script	
rule create_sparse_matrix:
	input:
		spliced = quant_path +'/quant/{SRS}/{tech}/{reference}/genecount/spliced.mtx', 
		unspliced = quant_path +'/quant/{SRS}/{tech}/{reference}/genecount/unspliced.mtx', 

	output:
		stats_spliced = quant_path + '/quant/{SRS}/{tech}/{reference}/genecount/stats.tsv',
		stats_unspliced = quant_path + '/quant/{SRS}/{tech}/{reference}/genecount/stats_unspliced.tsv',
		spliced_matrix = quant_path + '/quant/{SRS}/{tech}/{reference}/genecount/matrix.Rdata',
		unspliced_matrix = quant_path + '/quant/{SRS}/{tech}/{reference}/genecount/unspliced_matrix.Rdata'
	params:
		bus_out = lambda wildcards: f'{quant_path}/quant/{wildcards.SRS}/{wildcards.tech}/{wildcards.reference}/genecount/'
	group: "bus"	
	shell:
		"""
		module load R/3.6
		Rscript {git_dir}/src/remove_empty_UMI_make_sparse_matrix.R {wildcards.SRS} {wildcards.reference} {params.bus_out} {output.stats_spliced} {working_dir}

		"""		
# spit out both intron and exon counts 

rule merge_nonUMI_quant_by_organism:
	input:
		quant = lambda wildcards: expand(quant_path + '/quant/{SRS}/well/{{reference}}/abundance.tsv.gz', 
										SRS = [srs for srs in SRS_dict.keys() if SRS_dict[srs]['organism'] == wildcards.organism ] ),
		tx_map = 'references/velocity/well/{reference}/tr2g.tsv',
		gtf = 'references/gtf/{reference}_anno.gtf.gz'
	output:
		quant_path + '/quant/{organism}/well/{reference}__counts.Rdata',
		quant_path + '/quant/{organism}/well/{reference}__counts_tx.Rdata'
	shell:
		"""
		module load R/3.6
		Rscript {git_dir}/src/merge_nonUMI_quant_by_organism.R {output} {input.tx_map} {input.gtf} {quant_path} {wildcards.reference}
		"""

rule combine_well_and_umi:
	input:
		srr_metadata = config['srr_sample_file'],
		gtf='references/gtf/{reference}_anno.gtf.gz',
		spliced_counts = lambda wildcards: well_and_droplet_input(wildcards.organism, wildcards.reference, quant_path, SRS_dict, 
																	organism_welltech_dict, 'matrix.Rdata'),
		intron_counts = lambda wildcards: well_and_droplet_input(wildcards.organism, wildcards.reference, quant_path, SRS_dict, 
																	organism_welltech_dict, 'unspliced_matrix.Rdata')

	output:
		cell_info = 'pipeline_data/cell_info/{organism}_{reference}_cell_info.tsv',
		spliced_matrix = 'pipeline_data/clean_quant/{organism}/{reference}_full_sparse_matrix.Rdata',
		unspliced_matrix = 'pipeline_data/clean_quant/{organism}/{reference}_full_sparse_unspliced_matrix.Rdata',
		empty_droplets = 'pipeline_data/cell_info/{organism}_{reference}_empty_droplets.Rdata'  # note that this is the quant in the LOCAL directory
	shell:
		"""
		module load R/3.6
		Rscript {git_dir}/src/build_sparse_matrix.R {wildcards.organism} {output} {input.srr_metadata} {input.gtf} {input.spliced_counts}
		"""

rule merge_across_references:
	input:
		matrix = [ORG_ref(organism, 'matrix') for organism in ['Mus_musculus', 'Macaca_fascicularis', 'Homo_sapiens'] ],
		cell_info = [ORG_ref(organism, 'cell_info') for organism in ['Mus_musculus', 'Macaca_fascicularis', 'Homo_sapiens'] ]
	output:
		'pipeline_data/clean_quant/all_species_full_sparse_matrix.Rdata',
		'pipeline_data/clean_quant/all_species_full_sparse_unspliced_matrix.Rdata',
		'pipeline_data/cell_info/all_cell_info.tsv',
		'references/complete_id_mapping.tsv',
		expand('pipeline_data/clean_quant/{species}/full_sparse_matrix.Rdata',species= ['Homo_sapiens', 'Mus_musculus'])
	shell:
		"""
		module load R/3.6
		Rscript {git_dir}/src/blend_macaque_merge_across_reference.R {working_dir} {git_dir}
		"""	


rule label_known_cells_with_type:
	input:
		'pipeline_data/cell_info/all_cell_info.tsv',
		config['srr_sample_file']		
	output:
		'pipeline_data/cell_info/cell_info_labelled.Rdata'
	shell:
		"""
		module load R/3.6
		export SCIAD_CONFIG={config_abspath}
		Rscript {git_dir}/src/label_known_cells.R 
		"""

def get_fsm(parti):
	if parti in ['Homo_sapiens', "Mus_musculus"]:
		return f'pipeline_data/clean_quant/{parti}/full_sparse_matrix.Rdata' # species specific quant 
	else:
		return 'pipeline_data/clean_quant/all_species_full_sparse_matrix.Rdata'

seu_obj_pfx ='seurat_obj/'
seu_obj_param =['combination','add_intron','n_features}','transform','partition', 'covariate']
seu_obj_sfx = 'preFilter.seuratV3.Rdata'


rule make_seurat_objs:
	input:
		'pipeline_data/cell_info/all_cell_info.tsv',
		'pipeline_data/clean_quant/all_species_full_sparse_matrix.Rdata',		
		'pipeline_data/cell_info/cell_info_labelled.Rdata'
	output:
		seurat = 'seurat_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__preFilter.seuratV3.Rdata'
	shell:
		"""
		module load R/3.6
		export SCIAD_CONFIG={config_abspath}
		Rscript {git_dir}/src/build_seurat_obj_classic.R \
			{output.seurat} {wildcards.partition} {wildcards.covariate} {wildcards.transform} \
			{wildcards.combination} {wildcards.n_features} {input} 
		"""

intg_obj_pfx ='seurat_obj/'
intg_obj_param =['combination','add_intron','n_features}','transform','partition', 'covariate', 'method', 'dims']
intg_obj_sfx = 'preFilter.seuratV3.Rdata'
rule integrate_00:
	input:
		cell_label_info = 'pipeline_data/cell_info/cell_info_labelled.Rdata',
		obj = 'seurat_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__preFilter.seuratV3.Rdata',
	output:
		#temp('seurat_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter.seuratV3.Rdata')
		'seurat_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter.seuratV3.Rdata'
	threads: 2 	
	shell:
		'''
		module load R/3.6
		export SCIAD_CONDA_DIR={conda_dir}
		export SCIAD_GIT_DIR={git_dir}
		export SCIAD_CONFIG={config_abspath}
		cmd="Rscript {git_dir}/src/merge_methods.R \
				  {wildcards.method} \
				  {wildcards.transform} \
				  {wildcards.covariate} \
				  {wildcards.dims} \
				  {input.obj} \
				  {output}"
		
		echo $cmd 
		eval $cmd

		'''
	

rule calculate_umap:
	input:
		obj = 'seurat_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter.seuratV3.Rdata'
	output:
		'seurat_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist{dist}__nneighbors{neighbors}.umap.Rdata'
	threads: 4
	shell:
		"""
		module load R/3.6
		export SCIAD_CONDA_DIR={conda_dir}
		export SCIAD_GIT_DIR={git_dir}
		Rscript {git_dir}/src/calculate_umap_and_cluster.R \
			{wildcards.method} {wildcards.dims} {wildcards.dist} {wildcards.neighbors} 1 FALSE TRUE {input} {output}
		"""

rule calculate_tsne:
	input:
		obj = 'seurat_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter.seuratV3.Rdata'
	output:
		temp('seurat_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__perplexity{perplexity}.tsne.Rdata')
	threads: 4
	shell:
		"""
		module load R/3.6
		export SCIAD_FITSNE_DIR={fi_tsne_dir}
		Rscript {git_dir}/src/calculate_TSNE.R \
			{wildcards.method} {wildcards.dims} {wildcards.perplexity} {input} {output}
		"""

rule calculate_phate:
	input:
		obj = 'seurat_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter.seuratV3.Rdata'
	output:
		'phate/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter.phate.Rdata'
	threads: 16
	shell:
		"""
		module load R/3.6
		export SCIAD_CONDA_DIR={conda_dir}
		Rscript {git_dir}/src/run_phate.R {input} {output}
		"""
		
rule calculate_cluster:
	input:
		obj = 'seurat_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter.seuratV3.Rdata'
	output:
		temp('seurat_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__knn{knn}.cluster.seuratV3.Rdata')
	shell:
		"""
		module load R/3.6
		Rscript {git_dir}/src/calculate_umap_and_cluster.R \
			{wildcards.method} {wildcards.dims} 1 1 {wildcards.knn} TRUE FALSE {input} {output}
		"""

rule extract_umap:
	input:
		'seurat_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter.seuratV3.Rdata',
		'seurat_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist{dist}__nneighbors{neighbors}.umap.Rdata',
		'cluster/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__knn7.cluster.Rdata',
		'pipeline_data/cell_info/cell_info_labelled.Rdata'
		#'predictions/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter_cell_info_predictions.Rdata'
	output:
		'umap/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist{dist}__nneighbors{neighbors}.umap.Rdata'
	shell:
		"""
		module load R/3.6
		Rscript {git_dir}/src/extract_umap.R \
			{input} {output} {wildcards.method}	UMAP
		"""

rule extract_tsne:
	input:
		'seurat_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__perplexity{perplexity}.tsne.Rdata',
		'seurat_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__knn7.cluster.seuratV3.Rdata',
		'pipeline_data/cell_info/cell_info_labelled.Rdata'
		#'predictions/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter_cell_info_predictions.Rdata'
	output:
		'tsne/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__perplexity{perplexity}.tsne.Rdata'
	shell:
		"""
		module load R/3.6
		Rscript {git_dir}/src/extract_umap.R \
			{input} {output} {wildcards.method} TSNE
		"""

rule extract_cluster:
	input:
		'seurat_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__knn{knn}.cluster.seuratV3.Rdata'
	output:
		'cluster/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__knn{knn}.cluster.Rdata',
		'cluster/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__knn{knn}.graph.Rdata'
	shell:
		"""
		module load R/3.6
		Rscript {git_dir}/src/extract_cluster.R \
			{input} {output}
		"""

rule plot_integration:
	input:
		'umap/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist{dist}__nneighbors{neighbors}.umap.Rdata'
	output:
		'plots/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist{dist}__nneighbors{neighbors}.big_plot.png'
	shell:
		"""
		module load R/3.6
		Rscript {git_dir}/src/big_plots.R UMAP {input} {output}
		"""

rule plot_integration_tsne:
	input:
		'tsne/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__perplexity{perplexity}.tsne.Rdata'
	output:
		'plots/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__perplexity{perplexity}.big_tsne_plot.png'
	shell:
		"""
		module load R/3.6
		Rscript {git_dir}/src/big_plots.R TSNE {input} {output}
		"""

rule perf_metrics:
	input:
		'umap/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist0.3__nneighbors30.umap.Rdata',
		'seurat_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist0.3__nneighbors30.umap.Rdata',
		'cluster/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__knn{knn}.cluster.Rdata'
	output:
		'perf_metrics/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__knn{knn}.Rdata'
	shell:
		"""
		module load R/3.6
		Rscript {git_dir}/src/perf_metrics.R {input} {output}
		"""

rule make_h5ad_object:
	input:
		'umap/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist{dist}__nneighbors{neighbors}.umap.Rdata',
		'cluster/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__knn{knn}.cluster.Rdata',
		'seurat_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter.seuratV3.Rdata',
		'pipeline_data/cell_info/cell_info_labelled.Rdata',
		#'predictions/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter_cell_info_predictions.Rdata'
		#'monocle_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist{dist}__nneighbors{neighbors}__{knn}.monocle.Rdata'
	output:
		temp('anndata/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist{dist}__nneighbors{neighbors}__knn{knn}.h5ad')
	shell:
		"""
		module load R/3.6
		Rscript {git_dir}/src/seurat_to_h5ad.R {input} {output}
		"""

rule scIB_stats:
	input:
		 'anndata/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist{dist}__nneighbors{neighbors}__knn{knn}.h5ad'
	output:
		'scIB_stats/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist{dist}__nneighbors{neighbors}__knn{knn}___stats.csv'
	shell:
		"""
		module load R/3.6
		export SCIAD_CONDA_DIR={conda_dir}
		export SCIAD_GIT_DIR={git_dir}
		Rscript {git_dir}/src/scIB_stats.R {wildcards.method} {input} {wildcards.dims} {output}
		"""

rule quick_trajectory:
	input:
		'seurat_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter.seuratV3.Rdata',
		'cluster/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__knn{knn}.cluster.Rdata',
		'umap/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist{dist}__nneighbors{neighbors}.umap.Rdata'	
	output:
		'trajectory/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist{dist}__nneighbors{neighbors}__knn{knn}__quickTSCANmst.Rdata'
	shell:
		"""
		module load R/4.0
		Rscript ~/git/massive_integrated_eye_scRNA/src/trajectory_tscan.R {input} {wildcards.method} {output}
		"""

rule plot_quick_trajectory:
	input:
		'trajectory/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist{dist}__nneighbors{neighbors}__knn{knn}__quickTSCANmst.Rdata'
	output:
		'trajectory_plot/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist{dist}__nneighbors{neighbors}__knn{knn}__quickTSCANmst.png'
	shell:
		"""
		module load R/4.0
		Rscript ~/git/massive_integrated_eye_scRNA/src/trajectory_plot.R {input} {output}
		"""

rule centrality_quick_trajectory:
	input:
		'trajectory/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist{dist}__nneighbors{neighbors}__knn{knn}__quickTSCANmst.Rdata'
	output:
		'trajectory_metrics/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist{dist}__nneighbors{neighbors}__knn{knn}__centrality.tsv'
	shell:
		"""
		module load R/4.0
		Rscript ~/git/massive_integrated_eye_scRNA/src/trajectory_centrality.R {input} {output}
		"""

rule centrality_merge:
	input:
		parse_integration_config(file = config['integration_json'],
		output_string = 'trajectory_metrics/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist{dist}__nneighbors{neighbors}__knn{knn}__centrality.tsv', 
		which_partitions = ['TabulaDroplet']
		)
	output:
		'trajectory_metrics/merged.Rdata'
	shell:
		"""
		module load R/4.0
		Rscript  ~/git/massive_integrated_eye_scRNA/src/trajectory_centrality_merge.R {input} {output}
		"""


if config['subset_clustering'] == 'False':
	rule merge_stats:
		input:	
			parse_integration_config(file = config['integration_json'], 
			output_string ='perf_metrics/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__knn{knn}.Rdata',
			which_partitions = partitions_to_run ),
			
			parse_integration_config(file = config['integration_json'], 
			output_string ='scIB_stats/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist{dist}__nneighbors{neighbors}__knn{knn}___stats.csv', 
			which_partitions = ['universe', 'TabulaDroplet'] )
		output:
			'pipeline_data/results/merged_stats.Rdata'
		shell:
			"""
			module load R/3.6
			Rscript {git_dir}/src/optimal_params.R
			"""

else: 
	rule merge_stats:
		input:	
			parse_integration_config(file = config['integration_json'], 
			output_string ='perf_metrics/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__knn{knn}.Rdata',
			which_partitions =  ['celltype_subset'] ),
		
			parse_integration_config(file = config['integration_json'], 
			output_string ='scIB_stats/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist{dist}__nneighbors{neighbors}__knn{knn}___stats.csv', 
			which_partitions =  ['celltype_subset'])
		output:
			'pipeline_data/results/merged_stats.Rdata'
		shell:
			"""
			module load R/3.6
			Rscript {git_dir}/src/optimal_params.R
			"""
