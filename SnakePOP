#print('beginning of file')
import pprint
pp = pprint.PrettyPrinter(width=41, compact=True) 
import subprocess as sp
import tempfile
import yaml
import json
import string
import itertools
import time 
def dict_product(dicts):
	#https://stackoverflow.com/questions/11277432/how-to-remove-a-key-from-a-python-dictionary
    return (dict(zip(dicts, x)) for x in itertools.product(*dicts.values()))

## use a json to layout integration configs
def parse_integration_config(file, output_string, which_partitions):
	file_string = output_string
	rule_output =[]
	with open(file) as cfg_file:
		iconfig = json.load(cfg_file)
	gparam_dict={} 
	for key in iconfig['global_default']:
		gparam_dict[key] = iconfig['global_default'][key]
	
	for partition in which_partitions:
		default_params = gparam_dict.copy()
		## load default params and generate strings
		for param in iconfig[partition]['default']:
			default_params[param] = iconfig[partition]['default'][param]
		# for paritions that all have the same methods, ie subset clustering, its easier 
		# to add partition back to the default. 
		# This is so we dont over write it by accident
		if 'partition' not in default_params:
			default_params['partition'] = [partition]
		rule_output+=[file_string.format_map(dp) for dp in dict_product(default_params) ]
		## generate outptut for method with alternate params
		if len(iconfig[partition].keys()) > 1: # multiple methods
			methods = [m for m in iconfig[partition].keys() if m!= 'default']
			for method in methods:
				#reset default back to base for this
				base_default_params = default_params.copy()
				for param in iconfig[partition][method]:
					base_default_params[param] = iconfig[partition][method][param]
				# overwrite previous method
				base_default_params['method'] = [method]
				rule_output+=[file_string.format_map(dp) for dp in dict_product(base_default_params)]
	return rule_output

RSON_TEMP_DIR=config['rson_temp_dir']
## make sure lambda is in this order when using-  lambda wildcards, input, output
sp.run(f'mkdir -p {RSON_TEMP_DIR}',shell=True)
def export_rule_info(**kwargs):#
    with tempfile.NamedTemporaryFile( mode= 'w+',  prefix =RSON_TEMP_DIR, suffix ='.json', delete=False) as outjson:
        json.dump(kwargs, outjson)
        return outjson.name



# ALL_INTEGRATION_PARAMS = list(iconfig['global_default'].keys())
# for partition in iconfig.keys():
# 	if 'default' in  iconfig[partition]:
# 		for method in iconfig[partition].keys()
# 			ALL_INTEGRATION_PARAMS+=list(iconfig[partition][method].keys())
# ALL_INTEGRATION_PARAMS = 

def make_wc_string(pfx, wildcards, sfx, skip_db=None):
	## create a string with bracketed wildcards
	## skip_db - enable compatibility with expand:
	##   set skip_db to wc's that will be filled with expand, and then pass 
	##	 output to expand
	if skip_db is not None:
		lbr = '-{{'
		rbr = '}}__'
	else:
		lbr = '-{'
		rbr = '}__'
		skip_db=[]
	for wc in wildcards:
		if wc in skip_db:
			lbr = '-{'
			rbr = '}__'
		wc_str = wc + lbr + wc + rbr 
		pfx+= wc_str
	return pfx + sfx
# builds dictionary of dictionaries where first dict key is SRS 
# and second dict key are SRS properties
def metadata_builder(file, SRS_dict = {}, discrepancy = False):
	with open(file) as file:
		for line in file:
			if line[0] == '#':
				continue
			info = line.strip('\n').split('\t')
			if info[0] == 'sample_accession':
				continue
			SRS = info[0]
			if SRS not in SRS_dict:
				SRS_dict[SRS]={'SRR': [info[1]],
					    	  'paired':True if info[2]=='PAIRED' else False, 
					          'organism':info[3].replace(' ', '_'),
		            	      'tech':info[4],
						      'UMI':True if info[5]=='YES' else False,
							  'Study': info[6]}
			else:
				# this is mostly for SRA having the 'paired' status wrong
				# don't want to hand-edit the main metadata file
				# so I think better to create a new file with
				# hand edited values for just the ones i want to change
				if discrepancy:
					runs = SRS_dict[SRS]['SRR']
					SRS_dict[SRS] = {'SRR':runs,
									 'paired':True if info[2]=='PAIRED' else False,
									 'organism':info[3],
									 'tech':info[4],
									 'UMI':True if info[5]=='YES' else False,
									 'Study': info[6]}
				else:
					runs = SRS_dict[SRS]['SRR']
					runs.append(info[1])
					SRS_dict[SRS]['SRR'] = runs
	return(SRS_dict)
def lookup_run_from_SRS(SRS, fqp):
	SRR_files=SRS_dict[SRS]['SRR']
	out = []
	for SRR in SRR_files:
		if SRS_dict[SRS]['paired']:
			#PE
			out.append(f'{fqp}/fastq/{SRR}_1.fastq.gz')
			out.append(f'{fqp}/fastq/{SRR}_2.fastq.gz')
		else:
			#SE
			out.append(f'{fqp}/fastq/{SRR}.fastq.gz')
	return(out)


def SRP_2_SRS(quant_path, SRP, reference, sfx, srs_dict):
	out=[]
	for sample in srs_dict.keys():
		tech = srs_dict[sample]['tech']
		if srs_dict[sample]['Study'] == SRP and tech in ['DropSeq', '10xv2', '10xv3']:
			out.append(f'{quant_path}/quant/{sample}/{tech}/{reference}/genecount/{sfx}')
	return out


# return dummy well file for macaca ,as there is no well data at this time
# def OLDwell_and_droplet_input(organism, reference, quant_path, SRS_dict, otd, sfx):
# 	if organism == 'Macaca_fascicularis':
# 		out = [f'{quant_path}/quant/{srs}/{SRS_dict[srs]["tech"]}/{reference}/genecount/{sfx}' for srs in organism_droplet_dict[organism]]
# 	else:
# 		out = [f'{quant_path}/quant/{organism}/well/{reference}__counts.Rdata' ] + \
# 				[f'{quant_path}/quant/{srs}/{SRS_dict[srs]["tech"]}/{reference}/genecount/{sfx}' for srs in organism_droplet_dict[organism]]
# 	return(out)

def well_and_droplet_input(organism, reference, quant_path, SRP_droplet_dict, otd, sfx):
	target_srps = [ srp for srp in  SRP_droplet_dict.keys() if SRP_droplet_dict[srp]['organism'] == organism ] 
	if organism == 'Macaca_fascicularis':
		out = [f'pipeline_data/clean_quant/{srp}/{reference}/{sfx}' for srp in target_srps]
	else:
		out = [f'{quant_path}/quant/{organism}/well/{reference}__counts.Rdata' ] + \
				[f'pipeline_data/clean_quant/{srp}/{reference}/{sfx}' for srp in target_srps]
	return(out)




def REF_idx(organism, ref, org2tech):
	out = [f'references/velocity/{tech}/{ref}/tr2g.tsv' for tech in org2tech[organism]]
	return out



def ORG_ref(organism, which_return):
	if organism.lower() == 'mus_musculus':
		refs = ['mm-mus_musculus']
	elif organism.lower() == 'homo_sapiens':
		refs = ['hs-homo_sapiens']
	elif organism.lower() == 'macaca_fascicularis':
		refs = ['hs-homo_sapiens','mf-macaca_mulatta']
	else:
		print(organism + ' NO MATCH')
		exit()

	if which_return == 'matrix':
		out = [f'pipeline_data/clean_quant/{organism}/{ref}_full_sparse_matrix.Rdata' for ref in refs] + [f'pipeline_data/clean_quant/{organism}/{ref}_full_sparse_unspliced_matrix.Rdata' for ref in refs]
	else:
		out = [f'pipeline_data/cell_info/{organism}_{ref}_cell_info.tsv' for ref in refs]

	return(out)

srr_sample_file = config['srr_sample_file']
SRS_dict = metadata_builder(srr_sample_file)

# pp.pprint(SRS_dict)
# hand edited file which corrects mistakes that in the 
# various databases
# SRS_dict = metadata_builder(srr_sample_discrepancy_file, SRS_dict, discrepancy = True)

# build organism <-> SRS dict for nonUMI data
organism_well_dict = {}
organism_welltech_dict ={'Homo_sapiens':[], 'Mus_musculus':[], 'Macaca_fascicularis':[] }
		
	
for x in SRS_dict:
	if not SRS_dict[x]['UMI'] or not SRS_dict[x]['paired']:
		organism = SRS_dict[x]['organism']
		tech = SRS_dict[x]['tech']
		if tech not in organism_welltech_dict[organism]:
			organism_welltech_dict[organism].append(tech)
		if organism not in organism_well_dict:
			organism_well_dict[organism] = [x]
		else:
			srs = organism_well_dict[organism]
			srs.append(x)
			organism_well_dict[organism] = srs
# build organsim <-> SRS dict for UMI/droplet data
organism_droplet_dict = {}
droplet_samples = set()
srp_droplet_dict = dict()
for x in SRS_dict:
	if SRS_dict[x]['UMI'] and SRS_dict[x]['paired']:
		droplet_samples.add(x)
		organism = SRS_dict[x]['organism']
		study = SRS_dict[x]['Study']
		tech = SRS_dict[x]['tech']
		if study not in srp_droplet_dict:
			srp_droplet_dict[study] = {'tech':tech, 'organism':organism }
		if organism not in organism_droplet_dict:
			organism_droplet_dict[organism] = [x]
		else:
			srs = organism_droplet_dict[organism]
			srs.append(x)
			organism_droplet_dict[organism] = srs



git_dir = config['git_dir']
bustools_path = config['bustools_path']
working_dir = config['working_dir']
conda_dir = config['conda_dir']
fastq_path = config['fastq_path']
fi_tsne_dir = config['fi_tsne_dir']
quant_path = config['quant_path']
config_abspath=config['config_abspath']

SRS_UMI_samples = []
SRS_nonUMI_samples = []
for SRS in SRS_dict.keys():
	if SRS_dict[SRS]['UMI'] and SRS_dict[SRS]['paired']:
		SRS_UMI_samples.append(SRS)
	elif SRS_dict[SRS]['tech'] != 'BULK':
		SRS_nonUMI_samples.append(SRS)

method = ['scArches', 'bbknn','insct','magic', 'scVI','CCA', 'scanorama', 'harmony', 'fastMNN', 'combat', 'none', 'liger']
transform = ['libSize', 'sqrt', 'counts','standard', 'SCT','scran']
covariate = ['study_accession', 'batch']
organism = ['Mus_musculus', 'Macaca_fascicularis', 'Homo_sapiens']
combination = ['Mus_musculus', 'Mus_musculus_Macaca_fascicularis', 'Mus_musculus_Macaca_fascicularis_Homo_sapiens', 'universe']
dims = [4,6,8,10,20,25,30,50,75,100,200]
knn = [0.2,0,4,0.6, 5, 7, 10, 15]
model = ['A', 'B', 'C', 'D', 'E', 'F', 'G'] # A is ~seuratCluster+batch+percent.mt and B is ~seuratCluster+batch+percent.mt+organism
report: "report.rst"
wildcard_constraints:
	SRS = '|'.join(SRS_UMI_samples + SRS_nonUMI_samples),
	method = '|'.join(method),
	transform = '|'.join(transform),
	covariate = '|'.join(covariate),
	organism = '|'.join(organism),
	nfeatures = '|'.join([str(x) for x in [2000,5000]]),
	dims = '|'.join([str(x) for x in dims]),
	model = '|'.join(model)	

if config['subset_clustering'] == 'False':
	# partitions_to_run = ['universe', 'TabulaDroplet', 'onlyWELL']
	# scIB_partitions_to_run =  ['universe', 'TabulaDroplet'] 
	# Homo_sapiens/Mus_musculus are droplet only, species specific quantification
	partitions_to_run = [ 'TabulaDroplet', 'onlyWELL', "Homo_sapiens", "Mus_musculus"]
	scIB_partitions_to_run =  [ 'TabulaDroplet',"Homo_sapiens", "Mus_musculus"] 
else:
	partitions_to_run = ['celltype_subset']
	scIB_partitions_to_run = ['celltype_subset']

# start = time.time()
# seu_obj_param =['combination','add_intron','n_features','transform','partition', 'covariate']
# intg_obj_param = seu_obj_param + [ 'method', 'dims']
# umap_obj_param =intg_obj_param + ['dist', 'neighbors']
# extr_umap_param = umap_obj_param+['knn']
# perf_met_pfx ='pipeline_data/perf_metrics/'
# perf_met_param = extr_umap_param
# perf_met_sfx = 'perf.Rdata'
# parse_integration_config(file = config['integration_json'], 
# output_string =make_wc_string(perf_met_pfx, perf_met_param, perf_met_sfx),
# which_partitions = partitions_to_run )
# end = time.time()
# diff = str(end-start)
# print(f'{diff} seconds to generate final output')


rule all:
	input:
		'pipeline_data/results/merged_stats.Rdata'
	
# get annotation for each species 
rule download_annotation:
	output:
		mouse_anno='references/gtf/mm-mus_musculus_anno.gtf.gz',
		#macaque_faca_anno='references/gtf/macaca_fascicularis_anno.gtf.gz',
		macaque_mul_anno= 'references/gtf/mf-macaca_mulatta_anno.gtf.gz',
		human_anno='references/gtf/hs-homo_sapiens_anno.gtf.gz'
	shell:
		'''
		mkdir -p references
		wget -O {output.mouse_anno} ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.annotation.gtf.gz
		wget -O {output.mouse_genome} ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/GRCm38.primary_assembly.genome.fa.gz

		wget -O {output.macaque_mul_anno} ftp://ftp.ensembl.org/pub/release-99/gtf/macaca_mulatta/Macaca_mulatta.Mmul_10.99.gtf.gz
		wget -O {output.human_anno} ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_35/gencode.v35.annotation.gtf.gz
		'''
		#wget -O {output.macaque_faca_anno} ftp://ftp.ensembl.org/pub/release-98/gtf/macaca_fascicularis/Macaca_fascicularis.Macaca_fascicularis_5.0.98.gtf.gz


rule label_known_cells_with_type:
	input:
		'pipeline_data/cell_info/all_cell_info.tsv',
		config['srr_sample_file']		
	output:
		'pipeline_data/cell_info/cell_info_labelled.Rdata'
	shell:
		"""
		module load R/3.6
		export SCIAD_CONFIG={config_abspath}
		Rscript {git_dir}/src/label_known_cells.R 
		"""

def get_fsm(parti):
	if parti in ['Homo_sapiens', "Mus_musculus"]:
		return f'pipeline_data/clean_quant/{parti}/full_sparse_matrix.Rdata' # species specific quant 
	else:
		return 'pipeline_data/clean_quant/all_species_full_sparse_matrix.Rdata'




'''
integration parameter inheritance. Adding a wildcard upstream will add it for ALL rules below it 
seu_obj_param|
			 |-> intg_obj_param == phate_obj_param
			 				   |-> umap_obj_param| 
												 |->extr_umap_param ==  mk_h5ad_param == perf_met_param== q_traj_param == scIB_param == centrality*
							   |-> tsne_obj_param == extr_tsne_param
							   |-> clst_obj_param == extr_clst_param 

'''


seu_obj_pfx ='seurat_obj/raw/'
seu_obj_param =['n_features','transform','partition', 'covariate']
seu_obj_sfx = 'preFilter.seuratV3.Rdata'


rule make_seurat_objs:
	input:
		cell_info = 'pipeline_data/cell_info/all_cell_info.tsv',
		all_species_quant_file = 'pipeline_data/clean_quant/all_species_full_sparse_matrix.Rdata',
		labelled_cell_info = 'pipeline_data/cell_info/cell_info_labelled.Rdata'
	output:
		seurat = make_wc_string(seu_obj_pfx, seu_obj_param, seu_obj_sfx)
	params:
		rson = lambda wildcards, input, output: export_rule_info(input = dict(input), output=dict(output), wildcards = dict(wildcards))
	shell:
		"""
		module load R/3.6
		export SCIAD_CONFIG={config_abspath}
		Rscript {git_dir}/src/build_seurat_obj_classic.R {params.rson} {config_abspath}
		"""

intg_obj_pfx ='seurat_obj/integrated/'
intg_obj_param = seu_obj_param + [ 'method', 'dims']
intg_obj_sfx = 'preFilter.seuratV3.Rdata'

if 'scVI' in config['integration_json']:
	mm = 'merge_methods_scvi_ONLY.R'
else:
	mm = 'merge_methods.R'

rule integrate_00:
	input:
		cell_label_info = 'pipeline_data/cell_info/cell_info_labelled.Rdata',
		obj = make_wc_string(seu_obj_pfx, seu_obj_param, seu_obj_sfx)
	output:
		#temp('seurat_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter.seuratV3.Rdata')
		make_wc_string(intg_obj_pfx, intg_obj_param, intg_obj_sfx)
	threads: 2 	
	shell:
		"""

		module load R/3.6
		export SCIAD_CONDA_DIR={conda_dir}
		export SCIAD_GIT_DIR={git_dir}
		export SCIAD_CONFIG={config_abspath}
		cmd="Rscript {git_dir}/src/{mm} \
				  {wildcards.method} \
				  {wildcards.transform} \
				  {wildcards.covariate} \
				  {wildcards.dims} \
				  {input.obj} \
				  {output}"
		
		echo $cmd
		eval $cmd
		"""

umap_obj_pfx ='seurat_obj/integrated/'
umap_obj_param =intg_obj_param + ['dist', 'neighbors']
umap_obj_sfx = 'umap.seuratV3.Rdata'	
rule calculate_umap:
	input:
		obj = make_wc_string(intg_obj_pfx, intg_obj_param, intg_obj_sfx)
	output:
		make_wc_string(umap_obj_pfx, umap_obj_param, umap_obj_sfx)
	threads: 4
	shell:
		"""
		module load R/3.6
		export SCIAD_CONDA_DIR={conda_dir}
		export SCIAD_GIT_DIR={git_dir}
		Rscript {git_dir}/src/calculate_umap_and_cluster.R \
			{wildcards.method} {wildcards.dims} {wildcards.dist} {wildcards.neighbors} 1 FALSE TRUE {input} {output}
		"""

tsne_obj_pfx ='seurat_obj/integrated/'
tsne_obj_param = intg_obj_param + ['perplexity']
tsne_obj_sfx = 'tsne.seuratV3.Rdata'

rule calculate_tsne:
	input:
		obj = make_wc_string(intg_obj_pfx, intg_obj_param, intg_obj_sfx)
	output:
		temp(make_wc_string(tsne_obj_pfx, tsne_obj_param, tsne_obj_sfx))
	threads: 4
	shell:
		"""
		module load R/3.6
		export SCIAD_FITSNE_DIR={fi_tsne_dir}
		Rscript {git_dir}/src/calculate_TSNE.R \
			{wildcards.method} {wildcards.dims} {wildcards.perplexity} {input} {output}
		"""

phate_obj_pfx ='seurat_obj/integrated/'
phate_obj_param = intg_obj_param 
phate_obj_sfx = 'phate.seuratV3.Rdata'
rule calculate_phate:
	input:
		obj = make_wc_string(intg_obj_pfx, intg_obj_param, intg_obj_sfx)
	output:
		make_wc_string(phate_obj_pfx, phate_obj_param, phate_obj_sfx)
	threads: 16
	shell:
		"""
		module load R/3.6
		export SCIAD_CONDA_DIR={conda_dir}
		Rscript {git_dir}/src/run_phate.R {input} {output}
		"""

clst_obj_pfx ='seurat_obj/integrated/'
clst_obj_param = intg_obj_param  + ['knn']
clst_obj_sfx = 'cluster.seuratV3.Rdata'		
rule calculate_cluster:
	input:
		obj = make_wc_string(intg_obj_pfx, intg_obj_param, intg_obj_sfx)
	output:
		temp(make_wc_string(clst_obj_pfx, clst_obj_param, clst_obj_sfx))
	shell:
		"""
		module load R/3.6
		Rscript {git_dir}/src/calculate_umap_and_cluster.R \
			{wildcards.method} {wildcards.dims} 1 1 {wildcards.knn} TRUE FALSE {input} {output}
		"""

extr_clst_pfx ='pipeline_data/cluster/'
extr_clst_param = clst_obj_param
extr_clst_clst_sfx = 'cluster.Rdata'
extr_clst_grf_sfx = 'graph.Rdata'

rule extract_cluster:
	input:
		make_wc_string(clst_obj_pfx, clst_obj_param, clst_obj_sfx)
	output:
		make_wc_string(extr_clst_pfx, extr_clst_param, extr_clst_clst_sfx),
		make_wc_string(extr_clst_pfx, extr_clst_param, extr_clst_grf_sfx )
	shell:
		"""
		module load R/3.6
		Rscript {git_dir}/src/extract_cluster.R \
			{input} {output}
		"""


def set2mapper(set):
	if set == 'Homo_sapiens':
		return 'references/gtf/hs-homo_sapiens_anno.gtf.gz'
	elif set == 'Mus_musculus':
		return 'references/gtf/mm-mus_musculus_anno.gtf.gz'
	else:
		return 'references/ENSG2gene_name.tsv.gz'


extr_umap_pfx ='pipeline_data/umap/'
extr_umap_param = umap_obj_param+['knn']
extr_umap_sfx = 'umap.Rdata'		
rule extract_umap:
	input:
		intg_seu_obj = make_wc_string(intg_obj_pfx, intg_obj_param, intg_obj_sfx),
		umap_seu_obj = make_wc_string(umap_obj_pfx, umap_obj_param, umap_obj_sfx),
		cluster_rdata = make_wc_string(extr_clst_pfx, extr_clst_param, extr_clst_clst_sfx),
		cell_info_labeled = 'pipeline_data/cell_info/cell_info_labelled.Rdata',
		gene_id_mapper = lambda wildcards: set2mapper(wildcards.partition)
		#'predictions/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter_cell_info_predictions.Rdata'
	output:
		umap_data =make_wc_string(extr_umap_pfx, extr_umap_param, extr_umap_sfx)
	params:
		rson = lambda wildcards, input, output: export_rule_info(input = dict(input), output=dict(output), wildcards = dict(wildcards))
	shell:
		"""
		module load R/3.6
		Rscript {git_dir}/src/extract_umap.R {params.rson} UMAP
		"""
extr_tsne_pfx ='pipeline_data/tsne/'
extr_tsne_param = tsne_obj_param
extr_tsne_sfx = 'tsne.Rdata'
rule extract_tsne:
	input:
		make_wc_string(tsne_obj_pfx, tsne_obj_param, tsne_obj_sfx),
		make_wc_string(extr_clst_pfx, extr_clst_param, extr_clst_clst_sfx),
		'pipeline_data/cell_info/cell_info_labelled.Rdata'
		#'predictions/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter_cell_info_predictions.Rdata'
	output:
		make_wc_string(extr_tsne_pfx, extr_tsne_param, extr_tsne_sfx)
	shell:
		"""
		module load R/3.6
		Rscript {git_dir}/src/extract_umap.R \
			{input} {output} {wildcards.method} TSNE
		"""


plot_intr_umap_pfx ='pipeline_data/plots/'
plot_intr_umap_param = extr_umap_param
plot_intr_umap_sfx = 'umap.big_plot.png'

rule plot_integration:
	input:
		make_wc_string(extr_umap_pfx, extr_umap_param, extr_umap_sfx)
	output:
		make_wc_string(plot_intr_umap_pfx, plot_intr_umap_param, plot_intr_umap_sfx )
	shell:
		"""
		module load R/3.6
		Rscript {git_dir}/src/big_plots.R UMAP {input} {output}
		"""

plot_intr_tsne_pfx ='pipeline_data/plots/'
plot_intr_tsne_param = tsne_obj_param
plot_intr_tsne_sfx = 'tsne.big_plot.png'

rule plot_integration_tsne:
	input:
		make_wc_string(extr_tsne_pfx, extr_tsne_param, extr_tsne_sfx)
	output:
		make_wc_string(plot_intr_tsne_pfx, plot_intr_tsne_param, plot_intr_tsne_sfx)
	shell:
		"""
		module load R/3.6
		Rscript {git_dir}/src/big_plots.R TSNE {input} {output}
		"""

perf_met_pfx ='pipeline_data/perf_metrics/'
perf_met_param = extr_umap_param
perf_met_sfx = 'perf.Rdata'
parse_integration_config(file = config['integration_json'], 
output_string =make_wc_string(perf_met_pfx, perf_met_param, perf_met_sfx),
which_partitions = partitions_to_run )

rule perf_metrics:
	input:
		make_wc_string(extr_umap_pfx, extr_umap_param, extr_umap_sfx),
		make_wc_string(umap_obj_pfx, umap_obj_param, umap_obj_sfx),
		make_wc_string(extr_clst_pfx, extr_clst_param, extr_clst_clst_sfx)
	output:
		make_wc_string(perf_met_pfx, perf_met_param, perf_met_sfx)
	shell:
		"""
		module load R/3.6
		Rscript {git_dir}/src/perf_metrics.R {input} {output}
		"""
mk_h5ad_pfx ='anndata/'
mk_h5ad_param = extr_umap_param
mk_h5ad_sfx = '.h5ad'

rule make_h5ad_object:
	input:
		make_wc_string(extr_umap_pfx, extr_umap_param, extr_umap_sfx),
		make_wc_string(extr_clst_pfx, extr_clst_param, extr_clst_clst_sfx),
		make_wc_string(intg_obj_pfx, intg_obj_param, intg_obj_sfx),
		'pipeline_data/cell_info/cell_info_labelled.Rdata',
		#'predictions/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter_cell_info_predictions.Rdata'
		#'monocle_obj/{combination}__add_intron-{add_intron}__n_features{n_features}__{transform}__{partition}__{covariate}__{method}__dims{dims}__preFilter__mindist{dist}__nneighbors{neighbors}__{knn}.monocle.Rdata'
	output:
		make_wc_string(mk_h5ad_pfx, mk_h5ad_param, mk_h5ad_sfx)
	shell:
		"""
		export SCIAD_CONDA_DIR={conda_dir}
		module load R/3.6
		Rscript {git_dir}/src/seurat_to_h5ad.R {input} {output}
		"""

scIB_pfx ='pipeline_data/scIB/'
scIB_param = mk_h5ad_param
scIB_sfx = 'stats.csv'

rule scIB_stats:
	input:
		make_wc_string(mk_h5ad_pfx, mk_h5ad_param, mk_h5ad_sfx)
	output:
		make_wc_string(scIB_pfx, scIB_param, scIB_sfx)
	shell:
		"""
		module load R/3.6
		export SCIAD_CONDA_DIR={conda_dir}
		export SCIAD_GIT_DIR={git_dir}
		Rscript {git_dir}/src/scIB_stats.R {wildcards.method} {input} {wildcards.dims} {output}
		"""

q_traj_pfx ='pipeline_data/trajectory/data/'
q_traj_param = mk_h5ad_param
q_traj_sfx = 'quickTSCANmst.Rdata'
rule quick_trajectory:
	input:
		make_wc_string(intg_obj_pfx, intg_obj_param, intg_obj_sfx),
		make_wc_string(extr_clst_pfx, extr_clst_param, extr_clst_clst_sfx),
		make_wc_string(extr_umap_pfx, extr_umap_param, extr_umap_sfx)	
	output:
		make_wc_string(q_traj_pfx, q_traj_param, q_traj_sfx)
	shell:
		"""
		module load R/4.0
		Rscript{git_dir}/src/trajectory_tscan.R {input} {wildcards.method} {output}
		"""
plt_traj_pfx ='pipeline_data/trajectory/plot/'
plt_traj_param = mk_h5ad_param
plt_traj_sfx = 'quickTSCANmst.png'

rule plot_quick_trajectory:
	input:
		make_wc_string(q_traj_pfx, q_traj_param, q_traj_sfx)
	output:
		make_wc_string(plt_traj_pfx, plt_traj_param, plt_traj_sfx)
	shell:
		"""
		module load R/4.0
		Rscript {git_dir}/src/trajectory_plot.R {input} {output}
		"""

cntr_traj_pfx ='pipeline_data/trajectory/metrics/'
cntr_traj_param = mk_h5ad_param
cntr_traj_sfx = 'centrality.tsv'
rule centrality_quick_trajectory:
	input:
		make_wc_string(plt_traj_pfx, plt_traj_param, plt_traj_sfx)
	output:
		make_wc_string(cntr_traj_pfx, cntr_traj_param, cntr_traj_sfx)
	shell:
		"""
		module load R/4.0
		Rscript {git_dir}/src/trajectory_centrality.R {input} {output}
		"""
#this is for input
# cntr_mrg_pfx ='pipeline_data/trajectory/metrics/'
# cntr_mrg_param = mk_h5ad_param
# cntr_mrg_sfx = 'centrality.tsv'	
rule centrality_merge:
	input:
		parse_integration_config(file = config['integration_json'],
		output_string = make_wc_string(cntr_traj_pfx, cntr_traj_param, cntr_traj_sfx), 
		which_partitions = ['TabulaDroplet']
		)
	output:
		'trajectory_metrics/merged.Rdata'
	shell:
		"""
		module load R/4.0
		Rscript  {git_dir}/src/trajectory_centrality_merge.R {input} {output}
		"""

# for input 
# perf_met_pfx ='pipeline_data/perf_metrics/'
# perf_met_param = clst_obj_param
# perf_met_sfx = 'perf.Rdata'

# scIB_pfx ='pipeline_data/scIB/'
# scIB_param = mk_h5ad_param
# scIB_sfx = 'stats.csv'

rule merge_stats:
	input:	
		perf_data =parse_integration_config(file = config['integration_json'], 
												output_string =make_wc_string(perf_met_pfx, perf_met_param, perf_met_sfx),
												which_partitions = partitions_to_run ),
		scib_data = parse_integration_config(file = config['integration_json'], 
											output_string =make_wc_string(scIB_pfx, scIB_param, scIB_sfx), 
											which_partitions = scIB_partitions_to_run ),
		plot_integration = parse_integration_config(file = config['integration_json'], 
													output_string = make_wc_string(plot_intr_umap_pfx, plot_intr_umap_param, plot_intr_umap_sfx ),
													which_partitions = partitions_to_run)
	output:
		merged_stats = 'pipeline_data/results/merged_stats.Rdata'
	params: 
		rson = lambda wildcards, input, output: export_rule_info(input = dict(input), output=dict(output))
	shell:
		"""
		module load R/3.6
		Rscript {git_dir}/src/optimal_params.R {params.rson}
		"""