{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Query scEiaD with scVI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davemcg/scEiaD/blob/master/colab/cell_type_ML_labelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4nH3q_rZ0bI"
      },
      "source": [
        "# Querying scEiaD with scVI\n",
        "\n",
        "## tldr \n",
        "\n",
        "You can take your (retina) scRNA and overlay it onto [our](https://plae.nei.nih.gov) scEiaD (single cell Eye in a Disk) with minimuim fuss. This allows you to:\n",
        "\n",
        "## more reading\n",
        "1. Quickly check whether your sequencing worked (if most of your cells lay outside the known retina cell types...then likely something went wrong)\n",
        "2. Quickly see whether the cell types of the retina that you expect are present   \n",
        "  - a pan-retina scRNA will have very different proportions of the retinal cell types than a flow-sorted (for some marker) experiment\n",
        "3. Label your cell types by looking for overlaps between scEiaD and your data\n",
        "  - In the future we will also share our xgboost model so you can auto-label your data with our highly trained xgboost-based machine learning model. \n",
        "4. Is your organoid / cell line semi-comparable to primary tissue?\n",
        "\n",
        "## What does scVI do?\n",
        "Very briefly, the raw cell x gene expression counts (labelled only with the study/batch covariate) are given to scVI, which uses a [VAE](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73) to model the counts. The model can output batch corrected \"latent dimensions\" which are the equivalent of running a PCA on the counts.\n",
        "\n",
        "The scVI latent dimensions can be fed into the scanpy/Seurat/etc clustering/UMAP tools. \n",
        "\n",
        "A recent (version >= 0.8.0) update to scVI uses the \"scArches\" approach to encode the batches in a way that allows the model to be re-used with *new* data (that the scVI model has never seen). \n",
        "\n",
        "The Yosef Lab folks use the \"reference\" and \"query\" terms. In this case, reference is the scVI model built for scEiaD. Query is outside data. If you query (or project) your data with the scVI/scEiaD model, then you will get a set of latent dimensions that you use to make a UMAP visualization that will  approximate the one hosted at https://plae.nei.nih.gov. It won't be identical because the UMAP is run again with new data...in the future we will look into whether some of the new UMAP tools to update projections based on new data can be used. \n",
        "\n",
        "\n",
        "## Overview\n",
        "1. Install scvi and kallisto-bustools\n",
        "2. Download:\n",
        "  - our kallisto index\n",
        "  - our scVI model\n",
        "  - mini versions of the scEiaD\n",
        "4. Quantify SRA sample `SRR10887776` with kallisto-bustools (this is a retinal organoid...so this could get funky)\n",
        "5. Preprocess the h5ad object and glue scEiaD with SRR10887776\n",
        "6. Querying SRA dataset `SRR10887776` (merged with the scEiaD data) with scVI\n",
        "7. Visualize result\n",
        "8. Export result for Seurat usage\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a98iQc_Gwe7P"
      },
      "source": [
        "# Install scvi and kallisto-bustools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRTA1XIYZ0bN",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2bff04c-84db-4ab2-dd7b-93bb733b6515"
      },
      "source": [
        "import sys\n",
        "import re\n",
        "#if True, will install via pypi, else will install from source\n",
        "stable = True\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "if IN_COLAB and stable:\n",
        "    !pip install --quiet scvi-tools[tutorials]==0.9.0\n",
        "elif IN_COLAB and not stable:\n",
        "    !pip install --quiet --upgrade jsonschema\n",
        "    !pip install --quiet git+https://github.com/yoseflab/scvi-tools@master#egg=scvi-tools[tutorials]\n",
        "\n",
        "!pip install --quiet kb-python\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▉                              | 10kB 33.5MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20kB 35.4MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 30kB 21.3MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 40kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 51kB 26.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 61kB 29.6MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 71kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 81kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 92kB 19.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 102kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 112kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 122kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 133kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 143kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 153kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 163kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 174kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 20.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 849kB 50.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 11.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 59.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 634kB 55.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 49.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 64.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4MB 45.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 43.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.3MB 45.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.7MB 30.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 57.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 59.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 184kB 64.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 829kB 62.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 12.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 62.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3MB 56.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 11.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 54.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 62.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 296kB 63.0MB/s \n",
            "\u001b[?25h  Building wheel for loompy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for numpy-groupies (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 59.1MB 49kB/s \n",
            "\u001b[K     |████████████████████████████████| 13.2MB 244kB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "238VogqVd14K"
      },
      "source": [
        "# Download our kallisto index\n",
        "As our example set is human, we use the human Gencode v35 transcript reference.\n",
        "\n",
        "Nothing funky was done to make it, but the index creation requires around 32GB of memory, so it cannot be done in colab. Plus it takes 30 minutes or so. \n",
        "\n",
        "The index was created with this command:\n",
        "\n",
        "`kallisto index gencode.v35.transcripts.fa.gz -i gencode.v35.transcripts.idx`\n",
        "\n",
        "The transcript 2 gene file was made with this command:\n",
        "\n",
        "`zgrep \"^>\" gencode.v35.transcripts.fa.gz | sed 's/>//g' | awk 'BEGIN {OFS = \"\\t\"; FS = \"|\"}; {print $0, $2, $2}' | > v35.tr2g.tsv`\n",
        "\n",
        "and (to remove the .\\d ending from the ENSG)\n",
        "\n",
        "`cat v35.tr2g.tsv |  awk -F'\\t' -vOFS='\\t' '{ gsub(\"\\\\.[0-9]*\", \"\", $2) ; print }' | awk -F'\\t' -vOFS='\\t' '{ gsub(\"\\\\.[0-9]*\", \"\", $3) ; print }' > v35.tr2gX.tsv` \n",
        "\n",
        "\n",
        "(Download links):\n",
        "```\n",
        "https://hpc.nih.gov/~mcgaugheyd/scEiaD/colab/gencode.v35.transcripts.idx\n",
        "https://hpc.nih.gov/~mcgaugheyd/scEiaD/colab/v35.tr2gX.tsv\n",
        "\n",
        "https://hpc.nih.gov/~mcgaugheyd/scEiaD/colab/gencode.vM25.transcripts.idx\n",
        "https://hpc.nih.gov/~mcgaugheyd/scEiaD/colab/vM25.tr2gX.tsv\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC0naIRFwnG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5014a02-85e0-44f8-b4f9-a3b601c368d0"
      },
      "source": [
        "%%time\n",
        "!wget -O idx.idx https://hpc.nih.gov/~mcgaugheyd/scEiaD/colab/gencode.v35.transcripts.idx\n",
        "!wget -O t2g.txt https://hpc.nih.gov/~mcgaugheyd/scEiaD/colab/v35.tr2gx.tsv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-28 20:24:52--  https://hpc.nih.gov/~mcgaugheyd/scEiaD/colab/gencode.v35.transcripts.idx\n",
            "Resolving hpc.nih.gov (hpc.nih.gov)... 128.231.2.150, 2607:f220:418:4801::2:96\n",
            "Connecting to hpc.nih.gov (hpc.nih.gov)|128.231.2.150|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3204112341 (3.0G) [application/octet-stream]\n",
            "Saving to: ‘idx.idx’\n",
            "\n",
            "idx.idx             100%[===================>]   2.98G  27.6MB/s    in 54s     \n",
            "\n",
            "2021-04-28 20:25:48 (56.9 MB/s) - ‘idx.idx’ saved [3204112341/3204112341]\n",
            "\n",
            "--2021-04-28 20:25:48--  https://hpc.nih.gov/~mcgaugheyd/scEiaD/colab/v35.tr2gx.tsv\n",
            "Resolving hpc.nih.gov (hpc.nih.gov)... 128.231.2.150, 2607:f220:418:4801::2:96\n",
            "Connecting to hpc.nih.gov (hpc.nih.gov)|128.231.2.150|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34042406 (32M) [application/octet-stream]\n",
            "Saving to: ‘t2g.txt’\n",
            "\n",
            "t2g.txt             100%[===================>]  32.46M  65.3MB/s    in 0.5s    \n",
            "\n",
            "2021-04-28 20:25:49 (65.3 MB/s) - ‘t2g.txt’ saved [34042406/34042406]\n",
            "\n",
            "CPU times: user 500 ms, sys: 122 ms, total: 622 ms\n",
            "Wall time: 56.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImcF5LMLdl-Q"
      },
      "source": [
        "# Quantify with kbtools (Kallisto - Bustools wrapper) in one easy step.\n",
        "\n",
        "Going into the vagaries of turning a SRA deposit into a non-borked pair of fastq files is beyond the scope of this document. Plus I would swear a lot. So we just give an example set from a Human organoid retina 10x (version 2) experiment.\n",
        "\n",
        "The Pachter Lab has a discussion of how/where to get public data here: https://colab.research.google.com/github/pachterlab/kallistobustools/blob/master/notebooks/data_download.ipynb\n",
        "\n",
        "If you have your own 10X bam file, then 10X provides a very nice and simple tool to turn it into fastq file here: https://github.com/10XGenomics/bamtofastq\n",
        "\n",
        "To reduce run-time we have taken the first five million reads from this fastq pair.\n",
        "\n",
        "This will take ~3 minutes, depending on the internet speed between Google and our server\n",
        "\n",
        "You can also directly stream the file to improve wall-time, but I was getting periodic errors, so we are doing the simpler thing and downloading each fastq file here first.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odWwrzG9b8qJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b75012fa-790e-4cdc-cd7b-bc47bb41bfb1"
      },
      "source": [
        "%%time\n",
        "!wget -O sample_1.fastq.gz https://hpc.nih.gov/~mcgaugheyd/scEiaD/colab/SRR10887776_1.head.fastq.gz\n",
        "!wget -O sample_2.fastq.gz https://hpc.nih.gov/~mcgaugheyd/scEiaD/colab/SRR10887776_2.head.fastq.gz\n",
        "!kb count --overwrite --h5ad -i idx.idx -g t2g.txt -x DropSeq -o output --filter bustools -t 2 \\\n",
        "  sample_1.fastq.gz \\\n",
        "  sample_2.fastq.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-28 20:25:49--  https://hpc.nih.gov/~mcgaugheyd/scEiaD/colab/SRR10887776_1.head.fastq.gz\n",
            "Resolving hpc.nih.gov (hpc.nih.gov)... 128.231.2.150, 2607:f220:418:4801::2:96\n",
            "Connecting to hpc.nih.gov (hpc.nih.gov)|128.231.2.150|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149675347 (143M) [application/octet-stream]\n",
            "Saving to: ‘sample_1.fastq.gz’\n",
            "\n",
            "sample_1.fastq.gz   100%[===================>] 142.74M  53.7MB/s    in 2.7s    \n",
            "\n",
            "2021-04-28 20:25:52 (53.7 MB/s) - ‘sample_1.fastq.gz’ saved [149675347/149675347]\n",
            "\n",
            "--2021-04-28 20:25:54--  https://hpc.nih.gov/~mcgaugheyd/scEiaD/colab/SRR10887776_2.head.fastq.gz\n",
            "Resolving hpc.nih.gov (hpc.nih.gov)... 128.231.2.150, 2607:f220:418:4801::2:96\n",
            "Connecting to hpc.nih.gov (hpc.nih.gov)|128.231.2.150|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 374309257 (357M) [application/octet-stream]\n",
            "Saving to: ‘sample_2.fastq.gz’\n",
            "\n",
            "sample_2.fastq.gz   100%[===================>] 356.97M  48.4MB/s    in 6.5s    \n",
            "\n",
            "2021-04-28 20:26:01 (54.8 MB/s) - ‘sample_2.fastq.gz’ saved [374309257/374309257]\n",
            "\n",
            "[2021-04-28 20:26:06,684]    INFO Using index idx.idx to generate BUS file to output from\n",
            "[2021-04-28 20:26:06,684]    INFO         sample_1.fastq.gz\n",
            "[2021-04-28 20:26:06,684]    INFO         sample_2.fastq.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VcPiFtAjmbG"
      },
      "source": [
        "\n",
        "# Download our scEiaD anndata objects and scVI model\n",
        "\n",
        "scVI was first run on a human-only subset of the data to create a sensical arrangement of cell types (things can get weird when scVI has to handle celltypes, different studies, different technologies, AND different species). The mouse and macaque data were then projected onto it. So thus we will provide two (mini*) anndata objects: the human reference data (\"ref\") and the mouse/macaque data (\"query\").\n",
        "\n",
        "We will later glue the totally new data (SRR12130660) onto the query anndata object.\n",
        "\n",
        "\\* 12GB max memory usage here!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKv83AN6hcWO"
      },
      "source": [
        "%%time\n",
        "import scvi\n",
        "import scanpy as sc\n",
        "import pandas as pd \n",
        "#sc.set_figure_params(figsize=(8, 8))\n",
        "\n",
        "!wget -O scEiaD_ref.h5ad https://hpc.nih.gov/~mcgaugheyd/scEiaD/2021_03_17/scEiaD_all_anndata_mini_ref.h5ad\n",
        "!wget -O scEiaD_query.h5ad https://hpc.nih.gov/~mcgaugheyd/scEiaD/2021_03_17/scEiaD_all_anndata_mini_query.h5ad\n",
        "adata_scEiaD_ref = sc.read_h5ad('scEiaD_ref.h5ad')\n",
        "adata_scEiaD_query = sc.read_h5ad('scEiaD_query.h5ad')\n",
        "\n",
        "# Download the scEiaD scVI model and untar\n",
        "!wget -O scVI_scEiaD.tgz https://hpc.nih.gov/~mcgaugheyd/scEiaD/2021_03_17/2021_03_17__scVI_scEiaD.tgz\n",
        "!tar -xzf scVI_scEiaD.tgz\n",
        "# Set scVI model path\n",
        "scVI_model_dir_path = 'scVIprojectionSO_scEiaD_model/n_features-5000__transform-counts__partition-universe__covariate-batch__method-scVIprojectionSO__dims-8'\n",
        "# Read in HVG genes used in scVI model\n",
        "var_names = pd.read_csv(scVI_model_dir_path + '/var_names.csv', header = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMtDJca-SMht"
      },
      "source": [
        "# Load SRR12130660 h5ad\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VXKwVblMSEd"
      },
      "source": [
        "adata_query = sc.read_h5ad('output/counts_filtered/adata.h5ad')\n",
        "adata_query"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1H_tCFuxOua"
      },
      "source": [
        "# Glue together scEiaD query and the SRR12130660 query data\n",
        "scVI requires *only* the genes used to train the model to be in the anndata object. So we will cut down the anndata object `_HVG` for the scVI machine learning parts. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O70U0KN8tpie"
      },
      "source": [
        "%%time\n",
        "adata_query.obs['batch'] = 'New Data'\n",
        "adata_query.obs['query'] = 'New Data'\n",
        "adata_query.obs['CellType_predict'] = 'New Data'\n",
        "adata_scEiaD_ref.obs['query'] = 'scEiaD'\n",
        "adata_scEiaD_query.obs['query'] = 'scEiaD'\n",
        "\n",
        "# HVG only to merge\n",
        "adata_scEiaD_query_HVG = adata_scEiaD_query[:, var_names[0]]\n",
        "adata_query_HVG = adata_query[:, var_names[0]].copy()\n",
        "adata_query_HVG = adata_query.concatenate(adata_scEiaD_query, batch_key='bkey')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqGMJJHXyfDW"
      },
      "source": [
        "# intialize for scVI run\n",
        "adata_query_HVG = adata_query_HVG[:, var_names[0]].copy()\n",
        "scvi.data.setup_anndata(adata_query_HVG, batch_key=\"batch\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2PcDudixqTt"
      },
      "source": [
        "# Set up the scVI model\n",
        "Load the model (via `scVI_model_dir_path`) and feed it the anndata object we have been working on during this document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_RxbfnKJYtP"
      },
      "source": [
        "vae_query = scvi.model.SCVI.load_query_data(  \n",
        "    adata_query_HVG, \n",
        "    scVI_model_dir_path\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJyOL59_nAIQ"
      },
      "source": [
        "ls scVIprojectionSO_scEiaD_model/n_features-5000__transform-counts__partition-universe__covariate-batch__method-scVIprojectionSO__dims-8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMXg4_9Ex9g2"
      },
      "source": [
        "# Run scVI\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJoKQ4n6sbOx"
      },
      "source": [
        "%%time\n",
        "vae_query.train(max_epochs = 50, plan_kwargs=dict(n_epochs_kl_warmup=50, weight_decay=0.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqcGCy0SmXqw"
      },
      "source": [
        "# Extract latent dimensions with newly trained model\n",
        "Then glue together the ref and query anndata objects for UMAP making below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feqUsADRC8jz"
      },
      "source": [
        "%%time\n",
        "adata_scEiaD_ref_HVG = adata_scEiaD_ref[:,var_names[0]].copy()\n",
        "adata_full_HVG = adata_query_HVG.concatenate(adata_scEiaD_ref_HVG, batch_key = 'bkey')\n",
        "scvi.data.setup_anndata(adata_full_HVG, batch_key=\"batch\")\n",
        "del adata_full_HVG.uns[\"_scvi\"] # remove messed up internal scVI category from the concatenate\n",
        "adata_full_HVG.obsm['X_scvi'] = vae_query.get_latent_representation(adata_full_HVG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWsbkJ35yK_X"
      },
      "source": [
        "# Run Neighbor Finding and UMAP\n",
        "For the Seurat experts, the neighbor finding is built into the `RunUMAP` function. Notice how we explicitly give 'X_scvi' as the low dimensional space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVQI1S7NgEQf"
      },
      "source": [
        "%%time\n",
        "sc.pp.neighbors(adata_full_HVG, use_rep = 'X_scvi')\n",
        "sc.tl.umap(adata_full_HVG, min_dist=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FEA4DvNZXhX"
      },
      "source": [
        "# Plotting\n",
        "First plot shows the labelled cells from scEiaD *and* (in bright green?) the new dataset \n",
        "\n",
        "The second plot shows only the new organoid data\n",
        "\n",
        "The third plot shows scEiaD in orange and the organoid data in blue. \n",
        "\n",
        "We see how the new organoid data has many RPCs, amacrine cells, a few bipolar and retinal ganglia, and many photoreceptors.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_4oRjFc8QXm"
      },
      "source": [
        "%%time\n",
        "from matplotlib import rcParams\n",
        "sc.set_figure_params(dpi=150)\n",
        "rcParams['figure.figsize'] = 8, 8\n",
        "sc.pl.umap(adata_full_HVG, color = 'CellType_predict', add_outline=True, legend_loc='on data',  legend_fontsize=6)\n",
        "sc.pl.umap(adata_full_HVG[adata_full_HVG.obs['query'] != 'scEiaD'], color = 'CellType_predict', add_outline=True, legend_loc='on data',  legend_fontsize=6)\n",
        "sc.pl.umap(adata_full_HVG, color = 'query',legend_loc='on data', legend_fontsize=6, size = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JN1WMuUI6yJ"
      },
      "source": [
        "# Extract scVI latent dims and/or UMAP coords\n",
        "If you want to use the coords in Seurat, then here is an example how you could extract them to a text file for ingress into, say, Seurat."
      ]
    }
  ]
}